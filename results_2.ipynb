{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis (Part 1)\n",
    "\n",
    "This notebook takes the formats of the results that I gave for the WEAT tests and for the CNN and transforms to the format that we will be using for the analysis of the results for the paper.\n",
    "\n",
    "I'm assumming that you have an established naming convention given an embedding file ``[EMB]_[NAME]`` (where ``[EMB]`` is the type of embedding) and the WEAT test that was run. The convention I assumed was:\n",
    "- The embedding file has ``[EMB]`` somewhere in its name. I would also recommend to remove the extension, as this script adds that, but that's up to your naming conventions.\n",
    "- You gave each experiment a name ``[EXP]``.\n",
    "- The results from WEAT are in ``xweat/[EMB]_[NAME]_[EXP].res``\n",
    "- The results from the CNN are in:\n",
    "    - ``cnn/task1_[EXP].txt`` for general results\n",
    "    - ``cnn/task1_[EXP]\\_g1.txt`` for group 1\n",
    "    - ``cnn/task1_[EXP]\\_g2.txt`` for group 2\n",
    "    \n",
    "This is according to the naming convention I used in my scripts, it can be changed in the ``get_paths`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the packages we will be using\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the variables to the location of the results files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set here the path to the results\n",
    "path = \"./results/\"\n",
    "\n",
    "# I'm assuming that you have a folder for each of these, but that can be changed here\n",
    "cnn_path = path + \"cnn/\"\n",
    "weat_path = path + \"xweat/\"\n",
    "\n",
    "# The name of the file where we will save the results\n",
    "df_name = \"results_es.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have to give a tuple for each experiment. It must be of the form:\n",
    "\n",
    "``( embedding_file , experiment_name , weat_test )``\n",
    "\n",
    "If you add any extra information, try to add it after the ``weat_test`` value to avoid having to modify more than is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are adding experiments manually, use this\n",
    "experiments = [\n",
    "    (\"w2v_all_tweets_processed_es.tsv.vectors\", \"w2v_alltweets_t7\", \"7\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "# If you are adding the experiments straight from the experiment.txt file, use this\n",
    "experiments = []\n",
    "\n",
    "with open(\"experiment_1.txt\",mode=\"r\",encoding=\"utf-8\") as file:\n",
    "    for L in file:\n",
    "        line = L.split()\n",
    "        embeddings  = line[4]\n",
    "        exp_name    = line[2][1:-1]\n",
    "        weat_number = line[3]\n",
    "        # If we use normal weat, gives the number to it, otherwise states gender for es1 and migrant for es2\n",
    "        if weat_number == \"es1\":\n",
    "            weat_number = \"gender\"\n",
    "        elif weat_number == \"es2\":\n",
    "            weat_number = \"migrant\"\n",
    "        experiments.append((embeddings, exp_name, weat_number))\n",
    "\n",
    "# Make sure you have the right amount of experiments!\n",
    "print(len(experiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the paths to the WEAT results file that we used and to the CNN results. This is the function to modify if you used a different naming convention to those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(experiment, weat_path, cnn_path, cnn_files=[\"_g1.txt\",\"_g2.txt\"]):\n",
    "    \"\"\"\n",
    "    This is where the function builds the paths to things.\n",
    "    The weat_path and the cnn_path tell the program where to find those results\n",
    "    Assuming that the CNN results we want to compare only differ in a suffix of a filename, we use cnn_files\n",
    "    to be able to determine their locations. For example, if the files are \"RESULTS_g1.txt\" and \"RESULTS_g2.txt\",\n",
    "    we can give RESULTS as an argument and have cnn_files=[\"_g1.txt\",\"_g2.txt\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the info we passed for the experiment\n",
    "    emb = experiment[0]\n",
    "    exp = experiment[1]\n",
    "    tst = experiment[2]\n",
    "    \n",
    "    # Determine the paths to the files\n",
    "    weat_file = weat_path + emb + \"_\" + exp + \".res\"\n",
    "    cnn_file  = [cnn_path + \"task1_\" + exp + file for file in cnn_files]\n",
    "    \n",
    "    return weat_file, cnn_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads the WEAT test results given the path to the results file. It currently only gives back the EffectSize value, but it can be modified to also fetch the other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_weat_results(weat_file):\n",
    "    \"\"\"\n",
    "    Return the WEAT results.\n",
    "    \n",
    "    Input:\n",
    "        weat_file   A string that contains the path to the file that has the results\n",
    "        \n",
    "    Output:\n",
    "        EffectSize  The effect of the bias on the dataset. It is a float in the interval [-2, 2]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the file\n",
    "    data = list(map(\n",
    "                        lambda x: x.strip().lower().split(),\n",
    "                        open(weat_file,\"r\", encoding=\"utf8\").readlines()\n",
    "                       ))\n",
    "    \n",
    "    # Extract the results from the file\n",
    "    WeatStatistic = float(data[1][1][1:-1])\n",
    "    EffectSize    = float(data[1][2][:-1])\n",
    "    pValue        = float(data[1][3][:-1])\n",
    "    \n",
    "    return EffectSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the results from two runs of the CNN and return the values corresponding to the performance gaps of the metrics that we passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cnn_results(cnn_files, metrics=[\"precision\",\"recall\"]):\n",
    "    \"\"\"\n",
    "    A function that reads and returns the gaps between the preformance of two runs of the CNN model. A list of the\n",
    "    performance metrics to use can be passed.\n",
    "    \n",
    "    Input:\n",
    "\n",
    "        cnn_files   A list or list-like object where the first two elements are the paths to the two CNN results\n",
    "                    that we want to compare.\n",
    "        \n",
    "        metrics     A list or list-like object with the metrics that we want to compare. If using the CNN from the\n",
    "                    github user rimusa, the accepted values are: \"accuracy\", \"precision\", \"recall\", and \"f1-score\".\n",
    "                    The default value is metrics=[\"precision\",\"recall\"]\n",
    "                    \n",
    "    Output:\n",
    "        \n",
    "        A list containing the values for each metric in the form ( gap , metric )\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # If we do not have at least two files to compare, we cannot find the gap between them.\n",
    "    assert len(cnn_files) >= 2\n",
    "    \n",
    "    # Initialize the results list and the list that contains the gaps\n",
    "    results = [\"\",\"\"]\n",
    "    performance_gaps = []\n",
    "    \n",
    "    # We only read the first two files in the cnn_files list\n",
    "    for i in range(2):\n",
    "        \n",
    "        # Set the path to the current file\n",
    "        file = cnn_files[i]\n",
    "        \n",
    "        # Read the file\n",
    "        data = list(map(\n",
    "                    lambda x: x.strip().lower().split(),\n",
    "                    open(file,\"r\", encoding=\"utf8\").readlines()\n",
    "                   ))\n",
    "        \n",
    "        # Transforms the results to a dictionary\n",
    "        group = {}\n",
    "        for item in data:\n",
    "            key = item[0][:-1]\n",
    "            group[key] = item[1]\n",
    "            \n",
    "        # Stores the results\n",
    "        results[i] = group\n",
    "\n",
    "    # For each of our metrics, obtain the corresponding performance gap and save it\n",
    "    for metric in metrics:\n",
    "        gap = ( float(results[0][metric]) , float(results[1][metric] ) )\n",
    "        performance_gaps.append((gap, metric))\n",
    "    \n",
    "    # Returns the list of the performance gaps\n",
    "    return performance_gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we obtain the relevant rows of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_datapoint(weat_file, cnn_files, experiment):\n",
    "    \"\"\"\n",
    "    This function obtains the relevant data for each experiment.\n",
    "    \n",
    "    Input:\n",
    "        \n",
    "        weat_file   A string that contains the path to the file that has the results.\n",
    "        \n",
    "        cnn_files   A list or list-like object where the first two elements are the paths to the two CNN results\n",
    "                    that we want to compare.\n",
    "                    \n",
    "        experiment  A list or list-like object for the form\n",
    "                    [ embedding_file , experiment_name , weat_test ]\n",
    "                    \n",
    "    Output:\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    test = experiment[2]\n",
    "    emb_name = experiment[0]\n",
    "    \n",
    "    data1 = {}\n",
    "    data2 = {}\n",
    "    \n",
    "    data1[\"WEAT\"] = data2[\"WEAT\"] = read_weat_results(weat_file)\n",
    "    \n",
    "    results = read_cnn_results(cnn_files, metrics=[\"precision\",\"recall\"])\n",
    "    #print(results)\n",
    "    \n",
    "    data1[\"Performance Gender\"] = results[0][0][0]\n",
    "    data1[\"Performance Migrant\"] = results[0][0][1]\n",
    "    data1[\"Performance Gap\"] = results[0][0][0] - results[0][0][1]\n",
    "    data1[\"Metric\"] = results[0][1]\n",
    "    \n",
    "    data2[\"Performance Gender\"] = results[1][0][0]\n",
    "    data2[\"Performance G2\"] = results[1][0][1]\n",
    "    data2[\"Performance Gap\"] = results[1][0][0] - results[1][0][1]\n",
    "    data2[\"Metric\"] = results[1][1]\n",
    "    \n",
    "    data1[\"Test\"] = data2[\"Test\"] = test\n",
    "    \n",
    "    info = emb_name.lower().split(\"_\")\n",
    "    \n",
    "    if (\"ft\" in info) or (\"fasttext\" in info):\n",
    "        data1[\"Embedding\"] = \"fastText\"\n",
    "    elif (\"w2v\" in info) or (\"word2vec\" in info):\n",
    "        data1[\"Embedding\"] = \"word2vec\"\n",
    "    else:\n",
    "        warnings.warn(\"Embedding kind not recognized\\nCheck that the string before the first underscore are recognized\"+\n",
    "                      \" by the 'fetch_datapoint' method.\")\n",
    "    data2[\"Embedding\"] = data1[\"Embedding\"]\n",
    "    \n",
    "    data1[\"Name\"] = data2[\"Name\"] = emb_name + \".vectors\"\n",
    "        \n",
    "    return [data1, data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors found!\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "errors = 0\n",
    "\n",
    "for experiment in experiments:\n",
    "    try:\n",
    "        weat_file, cnn_files = get_paths(experiment, weat_path, cnn_path)\n",
    "        results += fetch_datapoint(weat_file, cnn_files, experiment)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error with test:\",experiment[1])\n",
    "        errors += 1\n",
    "    \n",
    "print(errors,\"errors found!\")\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results).to_csv(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
