Job running on landonia19
Job started: 09/11/2020 23:04:05
Setting up bash enviroment
Activating conda environment: gensim
Running provided command: bash scripts/experiment.sh "ft_retrain"  7 ft  false true false None
Creating the folder for the experiment
About to train the embeddings
Creating a temp folder in scratch space...
Copying data to scratch space...
sending incremental file list
tweets_processed.tsv

sent 101,470,862 bytes  received 35 bytes  67,647,264.67 bytes/sec
total size is 101,445,983  speedup is 1.00
Running embedding training script...
Identifying arguments
Training FastText embeddings
Generating embeddings...
Gensim implementation loaded

Creating embeddings model...
Model created

Generating vocabulary...
Vocabulary generated

Training embeddings model
Model trained:
FastText(vocab=52490, size=300, alpha=0.025) 

Embeddings saved


Copying embeddings back to headnode...
sending incremental file list
./

sent 67 bytes  received 19 bytes  172.00 bytes/sec
total size is 0  speedup is 0.00
Deleting data from scratch space...
/home/v1rmuoz2/embedding_bias/scripts
About to run WEAT test 7
Creating a temp folder in scratch space...
Copying data to scratch space...
sending incremental file list
ft_embeddings.300.vec

sent 183,816,186 bytes  received 35 bytes  73,526,488.40 bytes/sec
total size is 183,771,198  speedup is 1.00
Running WEAT script...
INFO:root:XWEAT started
INFO:root:Translating terms from en to es
INFO:root:Embeddings are in vec format
INFO:gensim.models.utils_any2vec:loading projection weights from /disk/scratch/v1rmuoz2/14014/weat_temp/data/ft_embeddings.300.vec
INFO:gensim.models.utils_any2vec:loaded (52490, 300) matrix from /disk/scratch/v1rmuoz2/14014/weat_temp/data/ft_embeddings.300.vec
INFO:root:Embeddings loaded
INFO:root:Running test
WARNING:root:Not in vocab de ella
WARNING:root:Not in vocab adici√≥n
INFO:root:Popped T2 26
INFO:root:Popped T2 25
INFO:root:Calculating p value ... 
INFO:root:Number of possible permutations: 924
INFO:root:(0.19288373, 0.6951717, 0.12987012987012986)
Copying results back to headnode...
sending incremental file list
./
ft_embeddings.300_ft_retrain.out
ft_embeddings.300_ft_retrain.res

sent 985 bytes  received 57 bytes  2,084.00 bytes/sec
total size is 773  speedup is 0.74
Deleting data from scratch space...
About to train the subtask 1 network
Creating a temp forder in scratch
Copying data to scratch space
sending incremental file list
./
.empty
hateval2019_clean_es_dev.csv
hateval2019_clean_es_test.csv
hateval2019_clean_es_train.csv
hateval2019_en_dev.csv
hateval2019_en_test.csv
hateval2019_en_train.csv
hateval2019_es_dev.csv
hateval2019_es_test.csv
hateval2019_es_train.csv
task1_es_dev.csv
task1_es_test.csv
task1_es_train.csv
task1_g1_dev.csv
task1_g1_test.csv
task1_g1_train.csv
task1_g2_dev.csv
task1_g2_test.csv
task1_g2_train.csv
task2_es_dev.csv
task2_es_test.csv
task2_es_train.csv
task2_g1_dev.csv
task2_g1_test.csv
task2_g1_train.csv
task2_g2_dev.csv
task2_g2_test.csv
task2_g2_train.csv

sent 8,884,802 bytes  received 551 bytes  5,923,568.67 bytes/sec
total size is 8,880,806  speedup is 1.00
sending incremental file list
./
Pipeline_Test_w2v_embeddings.300.vec
ft_embeddings.300.model
ft_embeddings.300.model.trainables.syn1neg.npy
ft_embeddings.300.model.trainables.vectors_ngrams_lockf.npy
ft_embeddings.300.model.trainables.vectors_vocab_lockf.npy
ft_embeddings.300.model.wv.vectors.npy
ft_embeddings.300.model.wv.vectors_ngrams.npy
ft_embeddings.300.model.wv.vectors_vocab.npy
ft_embeddings.300.txt
ft_embeddings.300.vec
w2v_embeddings.300.model
w2v_embeddings.300.model.trainables.syn1neg.npy
w2v_embeddings.300.model.wv.vectors.npy
w2v_embeddings.300.txt
w2v_embeddings.300.vec
mod_temp/

sent 6,073,702,894 bytes  received 312 bytes  102,079,045.48 bytes/sec
total size is 6,072,219,153  speedup is 1.00
ft_embeddings.300.model
ft_embeddings.300.model.trainables.syn1neg.npy
ft_embeddings.300.model.trainables.vectors_ngrams_lockf.npy
ft_embeddings.300.model.trainables.vectors_vocab_lockf.npy
ft_embeddings.300.model.wv.vectors_ngrams.npy
ft_embeddings.300.model.wv.vectors.npy
ft_embeddings.300.model.wv.vectors_vocab.npy
ft_embeddings.300.txt
ft_embeddings.300.vec
hateval2019_clean_es_dev.csv
hateval2019_clean_es_test.csv
hateval2019_clean_es_train.csv
hateval2019_en_dev.csv
hateval2019_en_test.csv
hateval2019_en_train.csv
hateval2019_es_dev.csv
hateval2019_es_test.csv
hateval2019_es_train.csv
mod_temp
Pipeline_Test_w2v_embeddings.300.vec
task1_es_dev.csv
task1_es_test.csv
task1_es_train.csv
task1_g1_dev.csv
task1_g1_test.csv
task1_g1_train.csv
task1_g2_dev.csv
task1_g2_test.csv
task1_g2_train.csv
task2_es_dev.csv
task2_es_test.csv
task2_es_train.csv
task2_g1_dev.csv
task2_g1_test.csv
task2_g1_train.csv
task2_g2_dev.csv
task2_g2_test.csv
task2_g2_train.csv
w2v_embeddings.300.model
w2v_embeddings.300.model.trainables.syn1neg.npy
w2v_embeddings.300.model.wv.vectors.npy
w2v_embeddings.300.txt
w2v_embeddings.300.vec
Training CNN
/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)
/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.
The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.
The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.

Loading data...
Traceback (most recent call last):
  File "./cnn/main.py", line 292, in <module>
    main()
  File "./cnn/main.py", line 244, in main
    vectors = vocab.Vectors(name=args.embeddings, cache='./cnn/')
  File "/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torchtext/vocab.py", line 319, in __init__
    self.cache(name, cache, url=url, max_vectors=max_vectors)
  File "/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torchtext/vocab.py", line 428, in cache
    self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)
  File "/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torch/serialization.py", line 584, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torch/serialization.py", line 842, in _load
    result = unpickler.load()
  File "/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torch/serialization.py", line 834, in persistent_load
    load_tensor(data_type, size, key, _maybe_decode_ascii(location))
  File "/home/v1rmuoz2/conda/envs/gensim/lib/python3.7/site-packages/torch/serialization.py", line 822, in load_tensor
    storage = zip_file.get_storage_from_record(name, size, dtype).storage()
RuntimeError: [enforce fail at inline_container.cc:209] . file not found: archive/data/94901284735264
